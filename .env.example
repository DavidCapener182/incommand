# Local LLM Configuration (Ollama)
# These variables are optional and only used when Ollama fallback is enabled
# Set these to configure a local or remote Ollama server and per-feature models

OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL_DEFAULT="llama3.2:latest"
OLLAMA_MODEL_DEBRIEF="llama3.2:latest"
OLLAMA_MODEL_SENTIMENT="llama3.2:latest"
